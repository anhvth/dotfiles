#!/usr/bin/env python3

import glob
import json
import argparse

# Import the read_by_ext function from the speedy module
from speedy import load_by_ext

def merge_files(file_pattern, output_file):
    # Glob the file pattern and sort
    files = sorted(glob.glob(file_pattern))
    if output_file is None:
        output_file = file_pattern.split('*')+'.json'
        logger.info(f'Set output_file {output_file=}')

    # Read files and concatenate the list
    all_data = []
    for file_name in files:
        print(file_name)
        # Use the read_by_ext function to read each file appropriately
        file_data = load_by_ext(file_name)
        if file_data is not None:
            all_data.extend(file_data)

    # Dump to output file
    try:
        with open(output_file, 'w') as f_out:
            json.dump(all_data, f_out, ensure_ascii=False)
        for path in files:
            import os
            os.remove(path)
            print(f'rm {path}')
    except Exception as e:
        from loguru import logger
        logger.error(e)
        
        

    print(f"Merged data saved to {output_file}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Merge files based on a pattern into a single output file.')
    parser.add_argument('file_pattern', type=str, help='File pattern to search for')
    parser.add_argument('--output_file', type=str, default='merged_results.json', help='Output file name')
    args = parser.parse_args()
    merge_files(args.file_pattern, args.output_file)
